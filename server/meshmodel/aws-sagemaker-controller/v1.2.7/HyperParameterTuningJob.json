{
  "id": "00000000-0000-0000-0000-000000000000",
  "kind": "HyperParameterTuningJob",
  "apiVersion": "sagemaker.services.k8s.aws/v1alpha1",
  "displayName": "Hyper Parameter Tuning Job",
  "format": "JSON",
  "hostID": "00000000-0000-0000-0000-000000000000",
  "metadata": {
   "isNamespaced": true
  },
  "model": {
   "id": "00000000-0000-0000-0000-000000000000",
   "name": "aws-sagemaker-controller",
   "version": "v1.2.7",
   "displayName": "aws-sagemaker-controller",
   "status": "",
   "hostID": "00000000-0000-0000-0000-000000000000",
   "category": {
    "name": "",
    "metadata": null
   },
   "metadata": {
    "source_uri": "git://github.com/aws-controllers-k8s/sagemaker-controller/main/helm"
   },
   "components": null,
   "relationships": null
  },
  "schema": "{\n \"description\": \"HyperParameterTuningJob is the Schema for the HyperParameterTuningJobs API\",\n \"properties\": {\n  \"spec\": {\n   \"description\": \"HyperParameterTuningJobSpec defines the desired state of HyperParameterTuningJob.\",\n   \"properties\": {\n    \"hyperParameterTuningJobConfig\": {\n     \"description\": \"The HyperParameterTuningJobConfig object that describes the tuning job, including\\nthe search strategy, the objective metric used to evaluate training jobs,\\nranges of parameters to search, and resource limits for the tuning job. For\\nmore information, see How Hyperparameter Tuning Works (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html).\",\n     \"properties\": {\n      \"hyperParameterTuningJobObjective\": {\n       \"description\": \"Defines the objective metric for a hyperparameter tuning job. Hyperparameter\\ntuning uses the value of this metric to evaluate the training jobs it launches,\\nand returns the training job that results in either the highest or lowest\\nvalue for this metric, depending on the value you specify for the Type parameter.\",\n       \"properties\": {\n        \"metricName\": {\n         \"type\": \"string\"\n        },\n        \"type_\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"parameterRanges\": {\n       \"description\": \"Specifies ranges of integer, continuous, and categorical hyperparameters\\nthat a hyperparameter tuning job searches. The hyperparameter tuning job\\nlaunches training jobs with hyperparameter values within these ranges to\\nfind the combination of values that result in the training job with the best\\nperformance as measured by the objective metric of the hyperparameter tuning\\njob.\\n\\n\\nThe maximum number of items specified for Array Members refers to the maximum\\nnumber of hyperparameters for each range and also the maximum for the hyperparameter\\ntuning job itself. That is, the sum of the number of hyperparameters for\\nall the ranges can't exceed the maximum number specified.\",\n       \"properties\": {\n        \"categoricalParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of categorical hyperparameters to tune.\",\n          \"properties\": {\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"values\": {\n            \"items\": {\n             \"type\": \"string\"\n            },\n            \"type\": \"array\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"continuousParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of continuous hyperparameters to tune.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"integerParameterRanges\": {\n         \"items\": {\n          \"description\": \"For a hyperparameter of the integer type, specifies the range that a hyperparameter\\ntuning job searches.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"resourceLimits\": {\n       \"description\": \"Specifies the maximum number of training jobs and parallel training jobs\\nthat a hyperparameter tuning job can launch.\",\n       \"properties\": {\n        \"maxNumberOfTrainingJobs\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"maxParallelTrainingJobs\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"strategy\": {\n       \"description\": \"The strategy hyperparameter tuning uses to find the best combination of hyperparameters\\nfor your model.\",\n       \"type\": \"string\"\n      },\n      \"trainingJobEarlyStoppingType\": {\n       \"type\": \"string\"\n      },\n      \"tuningJobCompletionCriteria\": {\n       \"description\": \"The job completion criteria.\",\n       \"properties\": {\n        \"targetObjectiveMetricValue\": {\n         \"type\": \"number\"\n        }\n       },\n       \"type\": \"object\"\n      }\n     },\n     \"type\": \"object\"\n    },\n    \"hyperParameterTuningJobName\": {\n     \"description\": \"The name of the tuning job. This name is the prefix for the names of all\\ntraining jobs that this tuning job launches. The name must be unique within\\nthe same Amazon Web Services account and Amazon Web Services Region. The\\nname must have 1 to 32 characters. Valid characters are a-z, A-Z, 0-9, and\\n: + = @ _ % - (hyphen). The name is not case sensitive.\",\n     \"type\": \"string\"\n    },\n    \"tags\": {\n     \"description\": \"An array of key-value pairs. You can use tags to categorize your Amazon Web\\nServices resources in different ways, for example, by purpose, owner, or\\nenvironment. For more information, see Tagging Amazon Web Services Resources\\n(https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html).\\n\\n\\nTags that you specify for the tuning job are also added to all training jobs\\nthat the tuning job launches.\",\n     \"items\": {\n      \"description\": \"A tag object that consists of a key and an optional value, used to manage\\nmetadata for SageMaker Amazon Web Services resources.\\n\\n\\nYou can add tags to notebook instances, training jobs, hyperparameter tuning\\njobs, batch transform jobs, models, labeling jobs, work teams, endpoint configurations,\\nand endpoints. For more information on adding tags to SageMaker resources,\\nsee AddTags.\\n\\n\\nFor more information on adding metadata to your Amazon Web Services resources\\nwith tagging, see Tagging Amazon Web Services resources (https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html).\\nFor advice on best practices for managing Amazon Web Services resources with\\ntagging, see Tagging Best Practices: Implement an Effective Amazon Web Services\\nResource Tagging Strategy (https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\",\n      \"properties\": {\n       \"key\": {\n        \"type\": \"string\"\n       },\n       \"value\": {\n        \"type\": \"string\"\n       }\n      },\n      \"type\": \"object\"\n     },\n     \"type\": \"array\"\n    },\n    \"trainingJobDefinition\": {\n     \"description\": \"The HyperParameterTrainingJobDefinition object that describes the training\\njobs that this tuning job launches, including static hyperparameters, input\\ndata configuration, output data configuration, resource configuration, and\\nstopping condition.\",\n     \"properties\": {\n      \"algorithmSpecification\": {\n       \"description\": \"Specifies which training algorithm to use for training jobs that a hyperparameter\\ntuning job launches and the metrics to monitor.\",\n       \"properties\": {\n        \"algorithmName\": {\n         \"type\": \"string\"\n        },\n        \"metricDefinitions\": {\n         \"items\": {\n          \"description\": \"Specifies a metric that the training algorithm writes to stderr or stdout.\\nSageMakerhyperparameter tuning captures all defined metrics. You specify\\none metric that a hyperparameter tuning job uses as its objective metric\\nto choose the best training job.\",\n          \"properties\": {\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"regex\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"trainingImage\": {\n         \"type\": \"string\"\n        },\n        \"trainingInputMode\": {\n         \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"checkpointConfig\": {\n       \"description\": \"Contains information about the output location for managed spot training\\ncheckpoint data.\",\n       \"properties\": {\n        \"localPath\": {\n         \"type\": \"string\"\n        },\n        \"s3URI\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"definitionName\": {\n       \"type\": \"string\"\n      },\n      \"enableInterContainerTrafficEncryption\": {\n       \"type\": \"boolean\"\n      },\n      \"enableManagedSpotTraining\": {\n       \"type\": \"boolean\"\n      },\n      \"enableNetworkIsolation\": {\n       \"type\": \"boolean\"\n      },\n      \"hyperParameterRanges\": {\n       \"description\": \"Specifies ranges of integer, continuous, and categorical hyperparameters\\nthat a hyperparameter tuning job searches. The hyperparameter tuning job\\nlaunches training jobs with hyperparameter values within these ranges to\\nfind the combination of values that result in the training job with the best\\nperformance as measured by the objective metric of the hyperparameter tuning\\njob.\\n\\n\\nThe maximum number of items specified for Array Members refers to the maximum\\nnumber of hyperparameters for each range and also the maximum for the hyperparameter\\ntuning job itself. That is, the sum of the number of hyperparameters for\\nall the ranges can't exceed the maximum number specified.\",\n       \"properties\": {\n        \"categoricalParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of categorical hyperparameters to tune.\",\n          \"properties\": {\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"values\": {\n            \"items\": {\n             \"type\": \"string\"\n            },\n            \"type\": \"array\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"continuousParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of continuous hyperparameters to tune.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"integerParameterRanges\": {\n         \"items\": {\n          \"description\": \"For a hyperparameter of the integer type, specifies the range that a hyperparameter\\ntuning job searches.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"inputDataConfig\": {\n       \"items\": {\n        \"description\": \"A channel is a named input source that training algorithms can consume.\",\n        \"properties\": {\n         \"channelName\": {\n          \"type\": \"string\"\n         },\n         \"compressionType\": {\n          \"type\": \"string\"\n         },\n         \"contentType\": {\n          \"type\": \"string\"\n         },\n         \"dataSource\": {\n          \"description\": \"Describes the location of the channel data.\",\n          \"properties\": {\n           \"fileSystemDataSource\": {\n            \"description\": \"Specifies a file system data source for a channel.\",\n            \"properties\": {\n             \"directoryPath\": {\n              \"type\": \"string\"\n             },\n             \"fileSystemAccessMode\": {\n              \"type\": \"string\"\n             },\n             \"fileSystemID\": {\n              \"type\": \"string\"\n             },\n             \"fileSystemType\": {\n              \"type\": \"string\"\n             }\n            },\n            \"type\": \"object\"\n           },\n           \"s3DataSource\": {\n            \"description\": \"Describes the S3 data source.\",\n            \"properties\": {\n             \"attributeNames\": {\n              \"items\": {\n               \"type\": \"string\"\n              },\n              \"type\": \"array\"\n             },\n             \"instanceGroupNames\": {\n              \"items\": {\n               \"type\": \"string\"\n              },\n              \"type\": \"array\"\n             },\n             \"s3DataDistributionType\": {\n              \"type\": \"string\"\n             },\n             \"s3DataType\": {\n              \"type\": \"string\"\n             },\n             \"s3URI\": {\n              \"type\": \"string\"\n             }\n            },\n            \"type\": \"object\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"inputMode\": {\n          \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n          \"type\": \"string\"\n         },\n         \"recordWrapperType\": {\n          \"type\": \"string\"\n         },\n         \"shuffleConfig\": {\n          \"description\": \"A configuration for a shuffle option for input data in a channel. If you\\nuse S3Prefix for S3DataType, the results of the S3 key prefix matches are\\nshuffled. If you use ManifestFile, the order of the S3 object references\\nin the ManifestFile is shuffled. If you use AugmentedManifestFile, the order\\nof the JSON lines in the AugmentedManifestFile is shuffled. The shuffling\\norder is determined using the Seed value.\\n\\n\\nFor Pipe input mode, when ShuffleConfig is specified shuffling is done at\\nthe start of every epoch. With large datasets, this ensures that the order\\nof the training data is different for each epoch, and it helps reduce bias\\nand possible overfitting. In a multi-node training job when ShuffleConfig\\nis combined with S3DataDistributionType of ShardedByS3Key, the data is shuffled\\nacross nodes so that the content sent to a particular node on the first epoch\\nmight be sent to a different node on the second epoch.\",\n          \"properties\": {\n           \"seed\": {\n            \"format\": \"int64\",\n            \"type\": \"integer\"\n           }\n          },\n          \"type\": \"object\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"type\": \"array\"\n      },\n      \"outputDataConfig\": {\n       \"description\": \"Provides information about how to store model training results (model artifacts).\",\n       \"properties\": {\n        \"kmsKeyID\": {\n         \"type\": \"string\"\n        },\n        \"s3OutputPath\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"resourceConfig\": {\n       \"description\": \"Describes the resources, including machine learning (ML) compute instances\\nand ML storage volumes, to use for model training.\",\n       \"properties\": {\n        \"instanceCount\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"instanceGroups\": {\n         \"items\": {\n          \"description\": \"Defines an instance group for heterogeneous cluster training. When requesting\\na training job using the CreateTrainingJob (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)\\nAPI, you can configure multiple instance groups .\",\n          \"properties\": {\n           \"instanceCount\": {\n            \"format\": \"int64\",\n            \"type\": \"integer\"\n           },\n           \"instanceGroupName\": {\n            \"type\": \"string\"\n           },\n           \"instanceType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"instanceType\": {\n         \"type\": \"string\"\n        },\n        \"keepAlivePeriodInSeconds\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"volumeKMSKeyID\": {\n         \"type\": \"string\"\n        },\n        \"volumeSizeInGB\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"retryStrategy\": {\n       \"description\": \"The retry strategy to use when a training job fails due to an InternalServerError.\\nRetryStrategy is specified as part of the CreateTrainingJob and CreateHyperParameterTuningJob\\nrequests. You can add the StoppingCondition parameter to the request to limit\\nthe training time for the complete job.\",\n       \"properties\": {\n        \"maximumRetryAttempts\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"roleARN\": {\n       \"type\": \"string\"\n      },\n      \"staticHyperParameters\": {\n       \"additionalProperties\": {\n        \"type\": \"string\"\n       },\n       \"type\": \"object\"\n      },\n      \"stoppingCondition\": {\n       \"description\": \"Specifies a limit to how long a model training job or model compilation job\\ncan run. It also specifies how long a managed spot training job has to complete.\\nWhen the job reaches the time limit, SageMaker ends the training or compilation\\njob. Use this API to cap model training costs.\\n\\n\\nTo stop a training job, SageMaker sends the algorithm the SIGTERM signal,\\nwhich delays job termination for 120 seconds. Algorithms can use this 120-second\\nwindow to save the model artifacts, so the results of training are not lost.\\n\\n\\nThe training algorithms provided by SageMaker automatically save the intermediate\\nresults of a model training job when possible. This attempt to save artifacts\\nis only a best effort case as model might not be in a state from which it\\ncan be saved. For example, if training has just started, the model might\\nnot be ready to save. When saved, this intermediate data is a valid model\\nartifact. You can use it to create a model with CreateModel.\\n\\n\\nThe Neural Topic Model (NTM) currently does not support saving intermediate\\nmodel artifacts. When training NTMs, make sure that the maximum runtime is\\nsufficient for the training job to complete.\",\n       \"properties\": {\n        \"maxRuntimeInSeconds\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"maxWaitTimeInSeconds\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"tuningObjective\": {\n       \"description\": \"Defines the objective metric for a hyperparameter tuning job. Hyperparameter\\ntuning uses the value of this metric to evaluate the training jobs it launches,\\nand returns the training job that results in either the highest or lowest\\nvalue for this metric, depending on the value you specify for the Type parameter.\",\n       \"properties\": {\n        \"metricName\": {\n         \"type\": \"string\"\n        },\n        \"type_\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"vpcConfig\": {\n       \"description\": \"Specifies a VPC that your training jobs and hosted models have access to.\\nControl access to and from your training and model containers by configuring\\nthe VPC. For more information, see Protect Endpoints by Using an Amazon Virtual\\nPrivate Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html)\\nand Protect Training Jobs by Using an Amazon Virtual Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).\",\n       \"properties\": {\n        \"securityGroupIDs\": {\n         \"items\": {\n          \"type\": \"string\"\n         },\n         \"type\": \"array\"\n        },\n        \"subnets\": {\n         \"items\": {\n          \"type\": \"string\"\n         },\n         \"type\": \"array\"\n        }\n       },\n       \"type\": \"object\"\n      }\n     },\n     \"type\": \"object\"\n    },\n    \"trainingJobDefinitions\": {\n     \"description\": \"A list of the HyperParameterTrainingJobDefinition objects launched for this\\ntuning job.\",\n     \"items\": {\n      \"description\": \"Defines the training jobs launched by a hyperparameter tuning job.\",\n      \"properties\": {\n       \"algorithmSpecification\": {\n        \"description\": \"Specifies which training algorithm to use for training jobs that a hyperparameter\\ntuning job launches and the metrics to monitor.\",\n        \"properties\": {\n         \"algorithmName\": {\n          \"type\": \"string\"\n         },\n         \"metricDefinitions\": {\n          \"items\": {\n           \"description\": \"Specifies a metric that the training algorithm writes to stderr or stdout.\\nSageMakerhyperparameter tuning captures all defined metrics. You specify\\none metric that a hyperparameter tuning job uses as its objective metric\\nto choose the best training job.\",\n           \"properties\": {\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"regex\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"trainingImage\": {\n          \"type\": \"string\"\n         },\n         \"trainingInputMode\": {\n          \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"checkpointConfig\": {\n        \"description\": \"Contains information about the output location for managed spot training\\ncheckpoint data.\",\n        \"properties\": {\n         \"localPath\": {\n          \"type\": \"string\"\n         },\n         \"s3URI\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"definitionName\": {\n        \"type\": \"string\"\n       },\n       \"enableInterContainerTrafficEncryption\": {\n        \"type\": \"boolean\"\n       },\n       \"enableManagedSpotTraining\": {\n        \"type\": \"boolean\"\n       },\n       \"enableNetworkIsolation\": {\n        \"type\": \"boolean\"\n       },\n       \"hyperParameterRanges\": {\n        \"description\": \"Specifies ranges of integer, continuous, and categorical hyperparameters\\nthat a hyperparameter tuning job searches. The hyperparameter tuning job\\nlaunches training jobs with hyperparameter values within these ranges to\\nfind the combination of values that result in the training job with the best\\nperformance as measured by the objective metric of the hyperparameter tuning\\njob.\\n\\n\\nThe maximum number of items specified for Array Members refers to the maximum\\nnumber of hyperparameters for each range and also the maximum for the hyperparameter\\ntuning job itself. That is, the sum of the number of hyperparameters for\\nall the ranges can't exceed the maximum number specified.\",\n        \"properties\": {\n         \"categoricalParameterRanges\": {\n          \"items\": {\n           \"description\": \"A list of categorical hyperparameters to tune.\",\n           \"properties\": {\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"values\": {\n             \"items\": {\n              \"type\": \"string\"\n             },\n             \"type\": \"array\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"continuousParameterRanges\": {\n          \"items\": {\n           \"description\": \"A list of continuous hyperparameters to tune.\",\n           \"properties\": {\n            \"maxValue\": {\n             \"type\": \"string\"\n            },\n            \"minValue\": {\n             \"type\": \"string\"\n            },\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"scalingType\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"integerParameterRanges\": {\n          \"items\": {\n           \"description\": \"For a hyperparameter of the integer type, specifies the range that a hyperparameter\\ntuning job searches.\",\n           \"properties\": {\n            \"maxValue\": {\n             \"type\": \"string\"\n            },\n            \"minValue\": {\n             \"type\": \"string\"\n            },\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"scalingType\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"inputDataConfig\": {\n        \"items\": {\n         \"description\": \"A channel is a named input source that training algorithms can consume.\",\n         \"properties\": {\n          \"channelName\": {\n           \"type\": \"string\"\n          },\n          \"compressionType\": {\n           \"type\": \"string\"\n          },\n          \"contentType\": {\n           \"type\": \"string\"\n          },\n          \"dataSource\": {\n           \"description\": \"Describes the location of the channel data.\",\n           \"properties\": {\n            \"fileSystemDataSource\": {\n             \"description\": \"Specifies a file system data source for a channel.\",\n             \"properties\": {\n              \"directoryPath\": {\n               \"type\": \"string\"\n              },\n              \"fileSystemAccessMode\": {\n               \"type\": \"string\"\n              },\n              \"fileSystemID\": {\n               \"type\": \"string\"\n              },\n              \"fileSystemType\": {\n               \"type\": \"string\"\n              }\n             },\n             \"type\": \"object\"\n            },\n            \"s3DataSource\": {\n             \"description\": \"Describes the S3 data source.\",\n             \"properties\": {\n              \"attributeNames\": {\n               \"items\": {\n                \"type\": \"string\"\n               },\n               \"type\": \"array\"\n              },\n              \"instanceGroupNames\": {\n               \"items\": {\n                \"type\": \"string\"\n               },\n               \"type\": \"array\"\n              },\n              \"s3DataDistributionType\": {\n               \"type\": \"string\"\n              },\n              \"s3DataType\": {\n               \"type\": \"string\"\n              },\n              \"s3URI\": {\n               \"type\": \"string\"\n              }\n             },\n             \"type\": \"object\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"inputMode\": {\n           \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n           \"type\": \"string\"\n          },\n          \"recordWrapperType\": {\n           \"type\": \"string\"\n          },\n          \"shuffleConfig\": {\n           \"description\": \"A configuration for a shuffle option for input data in a channel. If you\\nuse S3Prefix for S3DataType, the results of the S3 key prefix matches are\\nshuffled. If you use ManifestFile, the order of the S3 object references\\nin the ManifestFile is shuffled. If you use AugmentedManifestFile, the order\\nof the JSON lines in the AugmentedManifestFile is shuffled. The shuffling\\norder is determined using the Seed value.\\n\\n\\nFor Pipe input mode, when ShuffleConfig is specified shuffling is done at\\nthe start of every epoch. With large datasets, this ensures that the order\\nof the training data is different for each epoch, and it helps reduce bias\\nand possible overfitting. In a multi-node training job when ShuffleConfig\\nis combined with S3DataDistributionType of ShardedByS3Key, the data is shuffled\\nacross nodes so that the content sent to a particular node on the first epoch\\nmight be sent to a different node on the second epoch.\",\n           \"properties\": {\n            \"seed\": {\n             \"format\": \"int64\",\n             \"type\": \"integer\"\n            }\n           },\n           \"type\": \"object\"\n          }\n         },\n         \"type\": \"object\"\n        },\n        \"type\": \"array\"\n       },\n       \"outputDataConfig\": {\n        \"description\": \"Provides information about how to store model training results (model artifacts).\",\n        \"properties\": {\n         \"kmsKeyID\": {\n          \"type\": \"string\"\n         },\n         \"s3OutputPath\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"resourceConfig\": {\n        \"description\": \"Describes the resources, including machine learning (ML) compute instances\\nand ML storage volumes, to use for model training.\",\n        \"properties\": {\n         \"instanceCount\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         },\n         \"instanceGroups\": {\n          \"items\": {\n           \"description\": \"Defines an instance group for heterogeneous cluster training. When requesting\\na training job using the CreateTrainingJob (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)\\nAPI, you can configure multiple instance groups .\",\n           \"properties\": {\n            \"instanceCount\": {\n             \"format\": \"int64\",\n             \"type\": \"integer\"\n            },\n            \"instanceGroupName\": {\n             \"type\": \"string\"\n            },\n            \"instanceType\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"instanceType\": {\n          \"type\": \"string\"\n         },\n         \"keepAlivePeriodInSeconds\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         },\n         \"volumeKMSKeyID\": {\n          \"type\": \"string\"\n         },\n         \"volumeSizeInGB\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"retryStrategy\": {\n        \"description\": \"The retry strategy to use when a training job fails due to an InternalServerError.\\nRetryStrategy is specified as part of the CreateTrainingJob and CreateHyperParameterTuningJob\\nrequests. You can add the StoppingCondition parameter to the request to limit\\nthe training time for the complete job.\",\n        \"properties\": {\n         \"maximumRetryAttempts\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"roleARN\": {\n        \"type\": \"string\"\n       },\n       \"staticHyperParameters\": {\n        \"additionalProperties\": {\n         \"type\": \"string\"\n        },\n        \"type\": \"object\"\n       },\n       \"stoppingCondition\": {\n        \"description\": \"Specifies a limit to how long a model training job or model compilation job\\ncan run. It also specifies how long a managed spot training job has to complete.\\nWhen the job reaches the time limit, SageMaker ends the training or compilation\\njob. Use this API to cap model training costs.\\n\\n\\nTo stop a training job, SageMaker sends the algorithm the SIGTERM signal,\\nwhich delays job termination for 120 seconds. Algorithms can use this 120-second\\nwindow to save the model artifacts, so the results of training are not lost.\\n\\n\\nThe training algorithms provided by SageMaker automatically save the intermediate\\nresults of a model training job when possible. This attempt to save artifacts\\nis only a best effort case as model might not be in a state from which it\\ncan be saved. For example, if training has just started, the model might\\nnot be ready to save. When saved, this intermediate data is a valid model\\nartifact. You can use it to create a model with CreateModel.\\n\\n\\nThe Neural Topic Model (NTM) currently does not support saving intermediate\\nmodel artifacts. When training NTMs, make sure that the maximum runtime is\\nsufficient for the training job to complete.\",\n        \"properties\": {\n         \"maxRuntimeInSeconds\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         },\n         \"maxWaitTimeInSeconds\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"tuningObjective\": {\n        \"description\": \"Defines the objective metric for a hyperparameter tuning job. Hyperparameter\\ntuning uses the value of this metric to evaluate the training jobs it launches,\\nand returns the training job that results in either the highest or lowest\\nvalue for this metric, depending on the value you specify for the Type parameter.\",\n        \"properties\": {\n         \"metricName\": {\n          \"type\": \"string\"\n         },\n         \"type_\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"vpcConfig\": {\n        \"description\": \"Specifies a VPC that your training jobs and hosted models have access to.\\nControl access to and from your training and model containers by configuring\\nthe VPC. For more information, see Protect Endpoints by Using an Amazon Virtual\\nPrivate Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html)\\nand Protect Training Jobs by Using an Amazon Virtual Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).\",\n        \"properties\": {\n         \"securityGroupIDs\": {\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         },\n         \"subnets\": {\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         }\n        },\n        \"type\": \"object\"\n       }\n      },\n      \"type\": \"object\"\n     },\n     \"type\": \"array\"\n    },\n    \"warmStartConfig\": {\n     \"description\": \"Specifies the configuration for starting the hyperparameter tuning job using\\none or more previous tuning jobs as a starting point. The results of previous\\ntuning jobs are used to inform which combinations of hyperparameters to search\\nover in the new tuning job.\\n\\n\\nAll training jobs launched by the new hyperparameter tuning job are evaluated\\nby using the objective metric. If you specify IDENTICAL_DATA_AND_ALGORITHM\\nas the WarmStartType value for the warm start configuration, the training\\njob that performs the best in the new tuning job is compared to the best\\ntraining jobs from the parent tuning jobs. From these, the training job that\\nperforms the best as measured by the objective metric is returned as the\\noverall best training job.\\n\\n\\nAll training jobs launched by parent hyperparameter tuning jobs and the new\\nhyperparameter tuning jobs count against the limit of training jobs for the\\ntuning job.\",\n     \"properties\": {\n      \"parentHyperParameterTuningJobs\": {\n       \"items\": {\n        \"description\": \"A previously completed or stopped hyperparameter tuning job to be used as\\na starting point for a new hyperparameter tuning job.\",\n        \"properties\": {\n         \"hyperParameterTuningJobName\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"type\": \"array\"\n      },\n      \"warmStartType\": {\n       \"type\": \"string\"\n      }\n     },\n     \"type\": \"object\"\n    }\n   },\n   \"required\": [\n    \"hyperParameterTuningJobConfig\",\n    \"hyperParameterTuningJobName\"\n   ],\n   \"type\": \"object\"\n  }\n },\n \"title\": \"Hyper Parameter Tuning Job\",\n \"type\": \"object\"\n}"
 }